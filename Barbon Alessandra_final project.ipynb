{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4265555a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following preliminary analyses come from a Visual Search Task performed by two different samples: older vs younger adults.\n",
    "\n",
    "# In this particular task: \n",
    "# the set size of the stimuli presented varied according to 3 levels (5, 7 or 10 stimuli in total displayed);\n",
    "# the difficulty of the visual search also varied according to 3 levels \n",
    "### (Baseline, where stimuli could come from any conceptual category -such as kitchen materials, tools, clothing, ...- and any color category -such as blue, brown, black,...-;\n",
    "### High Concept, where stimuli could come only from one conceptual category but could be in different colors;\n",
    "### High Color, where stimuli could only be in one color but could come from different conceptual categories);\n",
    "# the Target that had to be searched for could be present or not.\n",
    "\n",
    "# Both Reaction Time (RT) and accuracy were measured.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from scipy.stats import ttest_ind  # LP: very minor but to keep code consistent you could have used stats.ttest_ind (or explicitely import all function like here)\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dcddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1. generation of some data\n",
    "\n",
    "# ensure reproducibility by putting a seed\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# LP: Veru nice definition of variables at top level; you could have done this for all variable though, and avoid\n",
    "# all numbers in the code loop below!\n",
    "# Also, you could have split the code into functions taking careof different parts of the data generation separately for readability\n",
    "# define variables levels\n",
    "Nfig_levels = [5, 7, 10]  \n",
    "Tipo_levels = ['Baseline', 'Hconc', 'Hcol'] \n",
    "TargetPresence_levels = ['T', 'NoT']\n",
    "Group_levels = ['OLD', 'YOUNG']\n",
    "\n",
    "# define the sample size\n",
    "n_samples = 30\n",
    "\n",
    "# define the number of participants per group\n",
    "n_participants_per_group = 30\n",
    "\n",
    "# define the total number of participants\n",
    "n_participants_tot = n_participants_per_group * len(Group_levels)\n",
    "\n",
    "# define the total number of trials for each combination of conditions\n",
    "total_trials_per_condition = 40\n",
    "\n",
    "# create a function for the data generation according to some boundaries\n",
    "def generate_ideal_data():\n",
    "    data = []\n",
    "    # initialize participant ID\n",
    "    participant_id = 1 \n",
    "    \n",
    "    # loop through each group level (YOUNG and OLD)\n",
    "    for group in Group_levels:\n",
    "        # loop through each participant within the group\n",
    "        for _ in range(n_participants_per_group):\n",
    "            # loop through each combination of Nfig, Tipo, and TargetPresence levels (so that it will generate RT and accuracy based on these combinations)\n",
    "            for Nfig, Tipo, TargetPresence in itertools.product(Nfig_levels, Tipo_levels, TargetPresence_levels): # itertools.product to generate all possible combinations of the levels of the independent variables\n",
    "                # define the baseline of RT according to the group\n",
    "                if group == 'YOUNG':\n",
    "                    base_rt = 0.71\n",
    "                else:  # Group == 'OLD'\n",
    "                    base_rt = 0.89\n",
    "                # YOUNG are faster than OLD\n",
    "                    \n",
    "                # generate RT as a function of the predictors\n",
    "                rt_nfig = (Nfig - 5) * 1.13  # increase by 1.45 for each additional level of difficulty compared to the easier level\n",
    "                rt_tipo = 0.91 if Tipo == 'Baseline' else (1.09 if Tipo == 'Hconc' else 1.2) # adjusting RT based on Tipo\n",
    "                rt_target = 0.8 if TargetPresence == 'T' else 1.56 # adjusting RT based on TargetPresence\n",
    "                rt_group = 0.97 if group == 'YOUNG' else 1.1 # adjusting RT based on Group\n",
    "                \n",
    "                # apply the baseline value\n",
    "                rt = base_rt * (1 + (rt_nfig + rt_tipo + rt_target + rt_group) / 100)\n",
    "                \n",
    "                # Add interaction effects (e.g., Tipo might interact with TargetPresence)\n",
    "                if Tipo != 'Baseline' and TargetPresence == 'NoT':\n",
    "                    rt += 0.15  # Increase RT for non-baseline tasks when target is not present\n",
    "\n",
    "                # Add some random noise for RT, with higher noise for more difficult tasks\n",
    "                difficulty = rt_nfig + rt_tipo + rt_target + rt_group\n",
    "                noise_level = 0.3 + 0.1 * (difficulty / 50)  # Increase noise with difficulty\n",
    "                rt += np.random.normal(0, noise_level)\n",
    "                \n",
    "                # add some random noise for RT\n",
    "                #rt += random.normalvariate(0, 0.3)\n",
    "                \n",
    "                # boundaries for RT (ex. no negative values but also not too close to 0)\n",
    "                rt = max(0.15, min(rt, 4))\n",
    "                \n",
    "                # Add small random buffer to avoid hitting the exact boundaries\n",
    "                if rt == 0.15:\n",
    "                    rt += np.random.uniform(0.01, 0.02)  # Slightly increase to avoid the lower boundary\n",
    "                if rt == 4:\n",
    "                    rt -= np.random.uniform(0.01, 0.02)  # Slightly decrease to avoid the upper boundary\n",
    "\n",
    "                # the resulting RT will be the mean RT for each participant for each condition combination\n",
    "                    \n",
    "                # define the baseline of Accuracy according to the group\n",
    "                if group == 'YOUNG':\n",
    "                    base_accuracy = 0.87\n",
    "                else:  # Group == 'OLD'\n",
    "                    base_accuracy = 0.96\n",
    "                # OLD are more accurate than YOUNG\n",
    "                \n",
    "                # generate accuracy as a function of the predictors\n",
    "                acc_nfig = -0.01 if Nfig == 5 else (-0.09 if Nfig == 7 else -0.13)  # adjust accuracy based on Nfig (decreasing with higher Nfig)\n",
    "                acc_tipo = 0.02 if Tipo == 'Baseline' else (-0.03 if Tipo == 'Hconc' else -0.06) # adjust accuracy based on Tipo\n",
    "                acc_target = 0 if TargetPresence == 'NoT' else -0.05 # adjust accuracy based on TargetPresence\n",
    "                acc_group = 0.03 if group == 'OLD' else -0.03 # adjust accuracy based on Group\n",
    "                \n",
    "                # apply the baseline value\n",
    "                accuracy = base_accuracy + acc_nfig + acc_tipo + acc_target + acc_group\n",
    "                \n",
    "                # Add interaction effects (e.g., Tipo might interact with TargetPresence)\n",
    "                if Tipo != 'Baseline' and TargetPresence == 'T':\n",
    "                    accuracy -= 0.02  # Decrease accuracy for non-baseline tasks when target is present\n",
    "\n",
    "                # Add some random noise for Accuracy, with higher noise for more difficult tasks\n",
    "                difficulty = abs(acc_nfig) + abs(acc_tipo) + abs(acc_target) + abs(acc_group)\n",
    "                noise_level = 0.05 + 0.02 * (difficulty / 0.5)  # Increase noise with difficulty\n",
    "                accuracy += np.random.normal(0, noise_level)\n",
    "                \n",
    "                # add some random noise for Accuracy\n",
    "                #accuracy += random.normalvariate(0, 0.3)\n",
    "                \n",
    "                # boundaries for Accuracy 0.65 e 1\n",
    "                accuracy = max(0.65, min(1, accuracy))\n",
    "                \n",
    "                # Add small random buffer to avoid hitting the exact boundaries\n",
    "                if accuracy == 0.65:\n",
    "                    accuracy += np.random.uniform(0.01, 0.02)  # Slightly increase to avoid the lower boundary\n",
    "                \n",
    "                # the resulting Accuracy will be the mean accuracy for each participant for each condition combination\n",
    "                \n",
    "                # calculate the number of correct trials based on accuracy\n",
    "                correct_trials = round(accuracy * total_trials_per_condition)\n",
    "                \n",
    "                data.append([participant_id, Nfig, Tipo, TargetPresence, group, rt, accuracy, correct_trials])\n",
    "            \n",
    "            participant_id += 1\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['ID', 'Nfig', 'Tipo', 'TargetPresence', 'Group', 'RT', 'Accuracy', 'correct_trials'])\n",
    "\n",
    "# generate data\n",
    "df_ideal = generate_ideal_data()\n",
    "\n",
    "print(df_ideal.head(50))\n",
    "print(df_ideal.tail(50))\n",
    "\n",
    "# Save to an Excel file\n",
    "df_ideal.to_excel('ideal_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2. T-test RT\n",
    "\n",
    "# t-test mean RT OLD vs YOUNG not considering any predictor\n",
    "rt_old = df_ideal[df_ideal['Group'] == 'OLD']['RT']\n",
    "rt_young = df_ideal[df_ideal['Group'] == 'YOUNG']['RT']\n",
    "\n",
    "t_stat, p_value = ttest_ind(rt_old, rt_young)\n",
    "print(f\"t-statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1988a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3. visualization of mean RT OLD vs YOUNG not considering any predictor\n",
    "\n",
    "# LP: Not bad code but you could have reduce it by exactly half defining functions for stats and plots (or a loop) and then iterated over the two groups!\n",
    "# Also, see comment in the next cells for jittered data points plotting \n",
    "\n",
    "# calculate mean RT and standard error for YOUNG and OLD\n",
    "mean_rt_young = df_ideal[df_ideal['Group'] == 'YOUNG']['RT'].mean()\n",
    "std_err_young = df_ideal[df_ideal['Group'] == 'YOUNG']['RT'].sem()\n",
    "mean_rt_old = df_ideal[df_ideal['Group'] == 'OLD']['RT'].mean()\n",
    "std_err_old = df_ideal[df_ideal['Group'] == 'OLD']['RT'].sem() \n",
    "print(f\"YOUNG mean RT: {mean_rt_young}, YOUNG SE: {std_err_young}\")\n",
    "print(f\"OLD mean RT: {mean_rt_old}, OLD SE: {std_err_old} \")\n",
    "\n",
    "# mean RT for each participant considering all conditions together\n",
    "mean_rt_young_ID = df_ideal[df_ideal['Group'] == 'YOUNG'].groupby('ID')['RT'].mean()\n",
    "mean_rt_old_ID = df_ideal[df_ideal['Group'] == 'OLD'].groupby('ID')['RT'].mean()\n",
    "\n",
    "# create a BAR plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['YOUNG', 'OLD'], [mean_rt_young, mean_rt_old], yerr=[std_err_young, std_err_old], capsize=5, color=['blue', 'violet'], label='Mean RT with SE')\n",
    "\n",
    "# in order to visualize also single data points, create a jitter for each participant's data point\n",
    "jitter_y = np.random.normal(loc=0, scale=0.05, size=len(mean_rt_young_ID))\n",
    "jitter_o = np.random.normal(loc=0, scale=0.05, size=len(mean_rt_old_ID))\n",
    "\n",
    "# add individual participant RTs as jittered data points\n",
    "plt.scatter(np.zeros(len(mean_rt_young_ID)) + jitter_y, mean_rt_young_ID, color='pink', alpha=0.5, label='Individual RT (YOUNG)')\n",
    "plt.scatter(np.ones(len(mean_rt_old_ID)) + jitter_o, mean_rt_old_ID, color='lightblue', alpha=0.5, label='Individual RT (OLD)')\n",
    "\n",
    "# following the t-test results, add significance star if any\n",
    "if p_value < 0.001:\n",
    "    sig = '***'  # Highly significant\n",
    "elif p_value < 0.01:\n",
    "    sig = '**'  # Very significant\n",
    "elif p_value < 0.05:\n",
    "    sig = '*'  # Significant\n",
    "else:\n",
    "    sig = 'n.s.'  # Not significant\n",
    "    \n",
    "# position of the star or \"n.s.\" is midway of the bars, slightly above the highest error bar\n",
    "plt.text(0.5, max(mean_rt_young + std_err_young, mean_rt_old + std_err_old) + 0.15, sig, ha='center', va='bottom', color='black', fontsize=20)\n",
    "\n",
    "# add line connecting the bars\n",
    "y_max = max(mean_rt_young + std_err_young, mean_rt_old + std_err_old) + 0.15\n",
    "plt.plot([0, 1], [y_max, y_max], color='black')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Mean Reaction Time (RT)')\n",
    "plt.title('Mean Reaction Time (RT) Comparison between YOUNG and OLD')\n",
    "plt.ylim(0.5, 1.4)  # Set y-axis range\n",
    "plt.xticks([0, 1], ['YOUNG', 'OLD'])\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# create a BOXPLOT\n",
    "plt.figure(figsize=(10, 6))\n",
    "data = [mean_rt_young_ID, mean_rt_old_ID]\n",
    "plt.boxplot(data, labels=['YOUNG', 'OLD'], patch_artist=True, boxprops=dict(facecolor='lightgrey', color='black', alpha=0.5), medianprops=dict(color='red'))\n",
    "\n",
    "# In order to visualize also single data points, create a jitter for each participant's data point\n",
    "jitter_y = np.random.normal(loc=1, scale=0.05, size=len(mean_rt_young_ID))\n",
    "jitter_o = np.random.normal(loc=2, scale=0.05, size=len(mean_rt_old_ID))\n",
    "\n",
    "# Add individual participant RTs as jittered data points\n",
    "plt.scatter(jitter_y, mean_rt_young_ID, color='pink', alpha=0.5, label='Individual RT (YOUNG)')\n",
    "plt.scatter(jitter_o, mean_rt_old_ID, color='lightblue', alpha=0.5, label='Individual RT (OLD)')\n",
    "\n",
    "# Following the t-test results, add significance star if any\n",
    "if p_value < 0.001:\n",
    "    sig = '***'  # Highly significant\n",
    "elif p_value < 0.01:\n",
    "    sig = '**'  # Very significant\n",
    "elif p_value < 0.05:\n",
    "    sig = '*'  # Significant\n",
    "else:\n",
    "    sig = 'n.s.'  # Not significant\n",
    "\n",
    "# Position of the star or \"n.s.\" is midway of the boxes, slightly above the highest box\n",
    "plt.text(1.5, max(mean_rt_young + std_err_young, mean_rt_old + std_err_old) + 0.15, sig, ha='center', va='bottom', color='black', fontsize=20)\n",
    "\n",
    "# Add line connecting the boxes\n",
    "y_max = max(mean_rt_young + std_err_young, mean_rt_old + std_err_old) + 0.15\n",
    "plt.plot([1, 2], [y_max, y_max], color='black')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Mean Reaction Time (RT)')\n",
    "plt.title('Mean Reaction Time (RT) Comparison between YOUNG and OLD')\n",
    "plt.ylim(0.5, 1.4)  # Set y-axis range\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4. checking assumptions for parametric methods\n",
    "\n",
    "# Assumption 1: Normality of the residuals\n",
    "shapiro_test_rt = stats.shapiro(df_ideal['RT'])\n",
    "print(f\"Shapiro-Wilk test for RT: statistic = {shapiro_test_rt.statistic}, p-value = {shapiro_test_rt.pvalue}\")\n",
    "\n",
    "# KIND AND CURIOUS QUESTION FOR WHO IS CURRENTLY LOOKING AT MY CODE:\n",
    "# HOW DO I MAKE IT POSSIBLE FOR THE RESIDUALS OF THE MODEL OF MY IDEAL DATA TO FOLLOW A NORMAL DISTRIBUTION?\n",
    "# LP: If you really want normal noise an optionis to generate \"pure\" datapoints with no randomness and then add noise from known distribution.\n",
    "# Not sure if this is what you want though!\n",
    "\n",
    "# MOREOVER, IN R I WOULD USE THE Aligned Rank Transform (ART) AS A NON-PARAMETRIC TECHNIQUE USED FOR FACTORIAL DATA ANALYSIS THROUGH THE PACKAGE ARTool BUT I DIDN'T FIND SOMETHING SIMILAR FOR PYTHON\n",
    "# WHAT SHOULD BE DONE IN MY CASE THAN?\n",
    "# LP: see below\n",
    "\n",
    "# Assumption 2: Homogeneity of variance\n",
    "levene_test = stats.levene(df_ideal['RT'][df_ideal['Group'] == 'YOUNG'],\n",
    "                            df_ideal['RT'][df_ideal['Group'] == 'OLD'])\n",
    "print(f\"Levene's test statistic: {levene_test.statistic}, p-value: {levene_test.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1be650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LP: # I do not know enough statistics to be of any help here, but here's an implementation that latest GPT offered, maybe it is worth compare the results with what you have in R :D\n",
    "# Please ping me with the results if you try this out.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from itertools import combinations\n",
    "\n",
    "def aligned_rank_transform(data, dependent_var, factors, interaction_order=None):\n",
    "    \"\"\"\n",
    "    Perform Aligned Rank Transform for Nonparametric Factorial ANOVAs,\n",
    "    including interactions up to the specified order.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data.\n",
    "    - dependent_var: string, name of the dependent variable.\n",
    "    - factors: list of strings, names of the independent factors.\n",
    "    - interaction_order: int or None, maximum order of interactions to include.\n",
    "                         If None, include all possible interactions.\n",
    "\n",
    "    Returns:\n",
    "    - art_data: DataFrame with aligned and ranked data.\n",
    "    \"\"\"\n",
    "    art_data = data.copy()\n",
    "    art_data['aligned'] = 0.0  # Initialize aligned data\n",
    "\n",
    "    # Generate all terms (main effects and interactions)\n",
    "    if interaction_order is None:\n",
    "        interaction_order = len(factors)\n",
    "    terms = []\n",
    "    for order in range(1, interaction_order + 1):\n",
    "        terms += ['*'.join(combo) for combo in combinations(factors, order)]\n",
    "\n",
    "    # Fit additive model with all specified interactions\n",
    "    formula = dependent_var + ' ~ ' + ' + '.join(terms)\n",
    "    model = ols(formula, data=data).fit()\n",
    "    aligned_values = model.fittedvalues\n",
    "\n",
    "    # Compute residuals\n",
    "    residuals = data[dependent_var] - aligned_values\n",
    "\n",
    "    # Add residuals to the grand mean to get aligned data\n",
    "    grand_mean = data[dependent_var].mean()\n",
    "    art_data['aligned'] = grand_mean + residuals\n",
    "\n",
    "    # Rank the aligned data\n",
    "    art_data['rank'] = art_data['aligned'].rank(method='average')\n",
    "\n",
    "    return art_data\n",
    "\n",
    "def anova_on_art(data, dependent_var='rank', factors=[], interaction_order=None):\n",
    "    \"\"\"\n",
    "    Perform ANOVA on the Aligned Rank Transformed data, including interactions.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the ART-transformed data.\n",
    "    - dependent_var: string, name of the ranked dependent variable.\n",
    "    - factors: list of strings, names of the independent factors.\n",
    "    - interaction_order: int or None, maximum order of interactions to include.\n",
    "                         Should match the order used in alignment.\n",
    "\n",
    "    Returns:\n",
    "    - anova_table: ANOVA results.\n",
    "    \"\"\"\n",
    "    # Generate all terms (main effects and interactions)\n",
    "    if interaction_order is None:\n",
    "        interaction_order = len(factors)\n",
    "    terms = []\n",
    "    for order in range(1, interaction_order + 1):\n",
    "        terms += ['*'.join(combo) for combo in combinations(factors, order)]\n",
    "\n",
    "    # Construct the formula for ANOVA\n",
    "    formula = dependent_var + ' ~ ' + ' * '.join(factors)\n",
    "    print(formula)\n",
    "    model = ols(formula, data=data).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    return anova_table\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Sample Data Creation\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'A': np.repeat(['Low', 'High'], 60),\n",
    "    'B': np.tile(np.repeat(['Control', 'Treatment'], 30), 2),\n",
    "    'Y': np.concatenate([\n",
    "        np.random.normal(10, 2, 30),\n",
    "        np.random.normal(12, 2, 30),\n",
    "        np.random.normal(15, 2, 30),\n",
    "        np.random.normal(17, 2, 30)\n",
    "    ])\n",
    "})\n",
    "\n",
    "# Apply Aligned Rank Transform with Interaction\n",
    "factors = ['Group', 'TargetPresence', 'Nfig', 'Tipo']\n",
    "interaction_order = 2  # For two-way interactions\n",
    "art_data = aligned_rank_transform(df_ideal, 'RT', factors, interaction_order=interaction_order)\n",
    "\n",
    "# Perform ANOVA on Ranked Data\n",
    "anova_results = anova_on_art(art_data, dependent_var='RT', factors=factors, interaction_order=interaction_order)\n",
    "\n",
    "print(\"Aligned Rank Transform ANOVA Results:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5. ANOVA (or non-parametric test)\n",
    "\n",
    "# create a formula for the ANOVA\n",
    "formula = 'RT ~ C(Group) + C(Nfig) + C(Tipo) + C(TargetPresence) + C(Group):C(Nfig) + C(Group):C(Tipo) + C(Group):C(TargetPresence) + C(Group):C(Nfig):C(Tipo) + C(Group):C(Nfig):C(TargetPresence) + C(Group):C(Tipo):C(TargetPresence)'\n",
    "\n",
    "model = ols(formula, df_ideal).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6. POST-HOC tests\n",
    "# LP: You know more stats than I do for sure :)\n",
    "\n",
    "# perform post-hoc test for 'Group'\n",
    "posthoc_group = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group'], alpha=0.05)\n",
    "print(posthoc_group)\n",
    "\n",
    "# perform post-hoc test for 'Nfig'\n",
    "posthoc_nfig = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Nfig'], alpha=0.05)\n",
    "print(posthoc_nfig)\n",
    "\n",
    "# perform post-hoc test for 'Tipo'\n",
    "posthoc_tipo = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Tipo'], alpha=0.05)\n",
    "print(posthoc_tipo)\n",
    "\n",
    "# perform post-hoc test for 'TargetPresence'\n",
    "posthoc_target_presence = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['TargetPresence'], alpha=0.05)\n",
    "print(posthoc_target_presence)\n",
    "\n",
    "# create interaction columns\n",
    "# LP: Probably the best here would have been a loop over pairs of interactor columns to avoid repetition\n",
    "df_ideal['Group_Nfig'] = df_ideal['Group'] + \"_\" + df_ideal['Nfig'].astype(str)\n",
    "df_ideal['Group_Tipo'] = df_ideal['Group'] + \"_\" + df_ideal['Tipo']\n",
    "df_ideal['Group_TargetPresence'] = df_ideal['Group'] + \"_\" + df_ideal['TargetPresence']\n",
    "df_ideal['Group_Nfig_Tipo'] = df_ideal['Group'] + \"_\" + df_ideal['Nfig'].astype(str) + \"_\" + df_ideal['Tipo']\n",
    "df_ideal['Group_Nfig_TargetPresence'] = df_ideal['Group'] + \"_\" + df_ideal['Nfig'].astype(str) + \"_\" + df_ideal['TargetPresence']\n",
    "df_ideal['Group_Tipo_TargetPresence'] = df_ideal['Group'] + \"_\" + df_ideal['Tipo'] + \"_\" + df_ideal['TargetPresence']\n",
    "\n",
    "# post-hoc test for 'Group:Nfig' interaction\n",
    "posthoc_group_nfig = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_Nfig'], alpha=0.05)\n",
    "print(posthoc_group_nfig)\n",
    "\n",
    "# post-hoc test for 'Group:Tipo' interaction\n",
    "posthoc_group_tipo = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_Tipo'], alpha=0.05)\n",
    "print(posthoc_group_tipo)\n",
    "\n",
    "# post-hoc test for 'Group:TargetPresence' interaction\n",
    "posthoc_group_target_presence = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_target_presence)\n",
    "\n",
    "# post-hoc test for 'Group:Nfig:Tipo' interaction\n",
    "posthoc_group_nfig_tipo = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_Nfig_Tipo'], alpha=0.05)\n",
    "print(posthoc_group_nfig_tipo)\n",
    "\n",
    "# post-hoc test for 'Group:Nfig:TargetPresence' interaction\n",
    "posthoc_group_nfig_target_presence = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_Nfig_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_nfig_target_presence)\n",
    "\n",
    "# post-hoc test for 'Group:Tipo:TargetPresence' interaction\n",
    "posthoc_group_tipo_target_presence = pairwise_tukeyhsd(df_ideal['RT'], df_ideal['Group_Tipo_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_tipo_target_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7. visualization of mean RT OLD vs YOUNG considering predictors interactions\n",
    "\n",
    "# LP: nice but no need for dynamite plots! :D\n",
    "# Also, very nice that you dag so much into plotting with jittering and all the alike but I would have written a specific function to deal with it!\n",
    "# It's likely you can need that code elsewhere in the future! :)\n",
    "\n",
    "# calculate the mean RT for each possible interaction of all levels of the conditions\n",
    "for Nfig in Nfig_levels:\n",
    "    for Tipo in Tipo_levels:\n",
    "        for TargetPresence in TargetPresence_levels:\n",
    "            for Group in Group_levels:\n",
    "                # filter the dataframe based on the current levels\n",
    "                df_filtered = df_ideal[(df_ideal['Nfig'] == Nfig) &\n",
    "                                                      (df_ideal['Tipo'] == Tipo) &\n",
    "                                                      (df_ideal['TargetPresence'] == TargetPresence) &\n",
    "                                                      (df_ideal['Group'] == Group)]\n",
    "                \n",
    "                # calculate the mean RT and standard error\n",
    "                mean_rt = df_filtered['RT'].mean()\n",
    "                std_err = df_filtered['RT'].sem()\n",
    "                \n",
    "                # Print the results\n",
    "                print(f\"Mean RT for Nfig={Nfig}, Tipo={Tipo}, TargetPresence={TargetPresence}, Group={Group}: {mean_rt}, SE: {std_err}\")\n",
    "\n",
    "# initialize a dictionary to store the jitter for each participant\n",
    "jitter_dict = {}\n",
    "\n",
    "# calculate the jitter for each possible interaction of all levels of the conditions\n",
    "for Nfig in Nfig_levels:\n",
    "    for Tipo in Tipo_levels:\n",
    "        for TargetPresence in TargetPresence_levels:\n",
    "            for Group in Group_levels:\n",
    "                # filter the dataframe based on the current levels\n",
    "                df_filtered = df_ideal[(df_ideal['Nfig'] == Nfig) &\n",
    "                                                      (df_ideal['Tipo'] == Tipo) &\n",
    "                                                      (df_ideal['TargetPresence'] == TargetPresence) &\n",
    "                                                      (df_ideal['Group'] == Group)]\n",
    "                \n",
    "                # get the unique participant IDs\n",
    "                IDs = df_filtered['ID'].unique()\n",
    "                \n",
    "                # calculate the jitter for each participant\n",
    "                for ID in IDs:\n",
    "                    jitter = np.random.normal(loc=0, scale=0.05)\n",
    "                    \n",
    "                    # store the jitter in the dictionary\n",
    "                    jitter_dict[(Nfig, Tipo, TargetPresence, Group, ID)] = jitter\n",
    "                    \n",
    "# create a new column that combines the Tipo and Nfig levels\n",
    "df_ideal['Tipo_Nfig'] = df_ideal['Tipo'] + '_' + df_ideal['Nfig'].astype(str)\n",
    "\n",
    "# create a dictionary to map Group to color\n",
    "color_dict = {'YOUNG': 'blue', 'OLD': 'violet'}\n",
    "color_dict2 = {'YOUNG': 'pink', 'OLD': 'lightblue'}\n",
    "\n",
    "# create two separate plots according to TargetPresence\n",
    "for TargetPresence in TargetPresence_levels:\n",
    "    # filter the DataFrame based on the current TargetPresence\n",
    "    df_filtered = df_ideal[df_ideal['TargetPresence'] == TargetPresence]\n",
    "    \n",
    "    # create a bar plot with error bars\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.barplot(data=df_filtered, x='Tipo_Nfig', y='RT', hue='Group', palette=color_dict, capsize=.1)\n",
    "    \n",
    "    # get the unique 'Tipo_Nfig' values\n",
    "    unique_Tipo_Nfig = df_filtered['Tipo_Nfig'].unique()\n",
    "    \n",
    "    # add individual participant mean RT as jittered data points\n",
    "    for Group in Group_levels:\n",
    "        for i, Tipo_Nfig in enumerate(unique_Tipo_Nfig):\n",
    "            # filter the dataframe based on the current 'Tipo_Nfig' and 'Group'\n",
    "            df_filtered_Tipo_Nfig_Group = df_filtered[(df_filtered['Tipo_Nfig'] == Tipo_Nfig) & (df_filtered['Group'] == Group)]\n",
    "            \n",
    "            # get the unique participant IDs\n",
    "            IDs = df_filtered_Tipo_Nfig_Group['ID'].unique()\n",
    "            \n",
    "            # plot the mean RT for each participant\n",
    "            for ID in IDs:\n",
    "                # introduce a horizontal offset for both 'Young' and 'Old' groups\n",
    "                offset = -0.2 if Group == 'OLD' else 0.2\n",
    "                # marker = 'x' if Group == 'YOUNG' else 'o'\n",
    "                plt.scatter(i + offset + jitter_dict[(Nfig, Tipo, TargetPresence, Group, ID)], df_filtered_Tipo_Nfig_Group[df_filtered_Tipo_Nfig_Group['ID'] == ID]['RT'].mean(), color=color_dict2[Group], alpha=0.5) #, marker=marker)\n",
    "    \n",
    "    plt.title(f'Mean Reaction Time (RT) for each condition (TargetPresence = {TargetPresence})')\n",
    "    plt.xlabel('Condition (Tipo_Nfig)')\n",
    "    plt.ylabel('Mean Reaction Time (RT)')\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "# create two separate BOXPLOTS according to TargetPresence\n",
    "for TargetPresence in TargetPresence_levels:\n",
    "    # filter the dataframe based on the current TargetPresence\n",
    "    df_filtered = df_ideal[df_ideal['TargetPresence'] == TargetPresence]\n",
    "    \n",
    "    # set size of the plot\n",
    "    plt.figure(figsize=(15, 8)) \n",
    "    # create a box plot with jittered data points\n",
    "    sns.boxplot(data=df_filtered, x='Tipo_Nfig', y='RT', hue='Group', palette=color_dict)\n",
    "    \n",
    "    \n",
    "    # get the unique 'Tipo_Nfig' values\n",
    "    unique_Tipo_Nfig = df_filtered['Tipo_Nfig'].unique()\n",
    "    \n",
    "    # add individual participant mean RT as jittered data points\n",
    "    for Group in Group_levels:\n",
    "        for i, Tipo_Nfig in enumerate(unique_Tipo_Nfig):\n",
    "            # filter the dataframe based on the current 'Tipo_Nfig' and 'Group'\n",
    "            df_filtered_Tipo_Nfig_Group = df_filtered[(df_filtered['Tipo_Nfig'] == Tipo_Nfig) & (df_filtered['Group'] == Group)]\n",
    "            \n",
    "            # get the unique participant IDs\n",
    "            IDs = df_filtered_Tipo_Nfig_Group['ID'].unique()\n",
    "            \n",
    "            # plot the mean RT for each participant\n",
    "            for ID in IDs:\n",
    "                # introduce a horizontal offset for both 'Young' and 'Old' groups\n",
    "                offset = -0.2 if Group == 'OLD' else 0.2\n",
    "                # marker = 'x' if Group == 'YOUNG' else 'o'\n",
    "                plt.scatter(i + offset + jitter_dict[(Nfig, Tipo, TargetPresence, Group, ID)], df_filtered_Tipo_Nfig_Group[df_filtered_Tipo_Nfig_Group['ID'] == ID]['RT'].mean(), color=color_dict2[Group], alpha=0.5) #, marker=marker) \n",
    "    \n",
    "    plt.ylim(0, 2)  # Set y-axis range\n",
    "    plt.title(f'Mean Reaction Time (RT) for each condition (TargetPresence = {TargetPresence})')\n",
    "    plt.xlabel('Condition (Tipo_Nfig)')\n",
    "    plt.ylabel('Mean Reaction Time (RT)')\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86206770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8. T-test Accuracy    \n",
    "    \n",
    "# t-test mean accuracy OLD vs YOUNG without considering predictors\n",
    "accuracy_old = df_ideal[df_ideal['Group'] == 'OLD']['Accuracy']\n",
    "accuracy_young = df_ideal[df_ideal['Group'] == 'YOUNG']['Accuracy']\n",
    "\n",
    "t_stat, p_value = ttest_ind(accuracy_old, accuracy_young)\n",
    "print(f\"t-statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050eb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9. visualization of mean Accuracy OLD vs YOUNG without considering predictors\n",
    "# LP: for example here !\n",
    "# Also, there is a huge amount of code duplication, and you are actually doing the same thing as above. Try to refactor it into a function!\n",
    "# your very nice code for adding significance could also go in a function \n",
    "\n",
    "# calculate mean accuracy + standard error for YOUNG & OLD\n",
    "mean_acc_young = df_ideal[df_ideal['Group'] == 'YOUNG']['Accuracy'].mean()\n",
    "std_err_acc_young = df_ideal[df_ideal['Group'] == 'YOUNG']['Accuracy'].sem()\n",
    "mean_acc_old = df_ideal[df_ideal['Group'] == 'OLD']['Accuracy'].mean()\n",
    "std_err_acc_old = df_ideal[df_ideal['Group'] == 'OLD']['Accuracy'].sem() \n",
    "print(f\"YOUNG mean Accuracy: {mean_acc_young}, YOUNG SE: {std_err_acc_young}\")\n",
    "print(f\"OLD mean Accuracy: {mean_acc_old}, OLD SE: {std_err_acc_old} \")\n",
    "\n",
    "# mean accuracy of each participant\n",
    "mean_acc_young_ID = df_ideal[df_ideal['Group'] == 'YOUNG'].groupby('ID')['Accuracy'].mean()\n",
    "mean_acc_old_ID = df_ideal[df_ideal['Group'] == 'OLD'].groupby('ID')['Accuracy'].mean()\n",
    "\n",
    "# create a BAR plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['YOUNG', 'OLD'], [mean_acc_young, mean_acc_old], yerr=[std_err_acc_young, std_err_acc_old], capsize=5, color=['blue', 'violet'], label='Mean Accuracy with SE')\n",
    "\n",
    "# create jitter for each participant data point\n",
    "jitter_y = np.random.normal(loc=0, scale=0.05, size=len(mean_acc_young_ID))\n",
    "jitter_o = np.random.normal(loc=0, scale=0.05, size=len(mean_acc_old_ID))\n",
    "\n",
    "# add individual participant accuracy as jittered data points\n",
    "plt.scatter(np.zeros(len(mean_acc_young_ID)) + jitter_y, mean_acc_young_ID, color='pink', alpha=0.5, label='Individual Accuracy (YOUNG)')\n",
    "plt.scatter(np.ones(len(mean_acc_old_ID)) + jitter_o, mean_acc_old_ID, color='lightblue', alpha=0.5, label='Individual Accuracy (OLD)')\n",
    "\n",
    "# add significance star\n",
    "if p_value < 0.001:\n",
    "    sig = '***'  # Highly significant\n",
    "elif p_value < 0.01:\n",
    "    sig = '**'  # Very significant\n",
    "elif p_value < 0.05:\n",
    "    sig = '*'  # Significant\n",
    "else:\n",
    "    sig = 'n.s.'  # Not significant\n",
    "    \n",
    "# position of the star or \"n.s.\" is midway of the bars, slightly above the highest error bar\n",
    "plt.text(0.5, max(mean_acc_young + std_err_acc_young, mean_acc_old + std_err_acc_old) + 0.1, sig, ha='center', va='bottom', color='black', fontsize=20)\n",
    "\n",
    "# add line connecting the bars\n",
    "y_max = max(mean_acc_young + std_err_acc_young, mean_acc_old + std_err_acc_old) + 0.1\n",
    "plt.plot([0, 1], [y_max, y_max], color='black')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Mean Accuracy Comparison between YOUNG and OLD')\n",
    "plt.ylim(0.6, 1)  # Set y-axis range\n",
    "plt.xticks([0, 1], ['YOUNG', 'OLD'])\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# create a BOXPLOT\n",
    "plt.figure(figsize=(10, 6))\n",
    "data_acc = [mean_acc_young_ID, mean_acc_old_ID]\n",
    "plt.boxplot(data_acc, labels=['YOUNG', 'OLD'], patch_artist=True, boxprops=dict(facecolor='lightgrey', color='black', alpha=0.5), medianprops=dict(color='red'))\n",
    "\n",
    "# In order to visualize also single data points, create a jitter for each participant's data point\n",
    "jitter_y = np.random.normal(loc=1, scale=0.05, size=len(mean_acc_young_ID))\n",
    "jitter_o = np.random.normal(loc=2, scale=0.05, size=len(mean_acc_old_ID))\n",
    "\n",
    "# Add individual participant RTs as jittered data points\n",
    "plt.scatter(jitter_y, mean_acc_young_ID, color='pink', alpha=0.5, label='Individual RT (YOUNG)')\n",
    "plt.scatter(jitter_o, mean_acc_old_ID, color='lightblue', alpha=0.5, label='Individual RT (OLD)')\n",
    "\n",
    "# Following the t-test results, add significance star if any\n",
    "if p_value < 0.001:\n",
    "    sig = '***'  # Highly significant\n",
    "elif p_value < 0.01:\n",
    "    sig = '**'  # Very significant\n",
    "elif p_value < 0.05:\n",
    "    sig = '*'  # Significant\n",
    "else:\n",
    "    sig = 'n.s.'  # Not significant\n",
    "\n",
    "# position of the star or \"n.s.\" is midway of the bars, slightly above the highest error bar\n",
    "plt.text(1.5, max(mean_acc_young + std_err_acc_young, mean_acc_old + std_err_acc_old) + 0.1, sig, ha='center', va='bottom', color='black', fontsize=20)\n",
    "\n",
    "# add line connecting the bars\n",
    "y_max = max(mean_acc_young + std_err_acc_young, mean_acc_old + std_err_acc_old) + 0.1\n",
    "plt.plot([1, 2], [y_max, y_max], color='black')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Mean Accuracy Comparison between YOUNG and OLD')\n",
    "plt.ylim(0.6, 1)  # Set y-axis range\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10. checking assumptions for parametric methods\n",
    "\n",
    "# Assumption 1: Normality\n",
    "shapiro_test_accuracy = stats.shapiro(df_ideal['Accuracy'])\n",
    "print(f\"Shapiro-Wilk test for Accuracy: statistic = {shapiro_test_accuracy.statistic}, p-value = {shapiro_test_accuracy.pvalue}\")\n",
    "\n",
    "# Assumption 2: Homogeneity of variance\n",
    "levene_test_acc = stats.levene(df_ideal['Accuracy'][df_ideal['Group'] == 'YOUNG'],\n",
    "                            df_ideal['Accuracy'][df_ideal['Group'] == 'OLD'])\n",
    "print(f\"Levene's test statistic: {levene_test_acc.statistic}, p-value: {levene_test_acc.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11. ANOVA (or non-parametric test)\n",
    "\n",
    "# create a formula for the ANOVA\n",
    "formula2 = 'Accuracy ~ C(Group) + C(Nfig) + C(Tipo) + C(TargetPresence) + C(Group):C(Nfig) + C(Group):C(Tipo) + C(Group):C(TargetPresence) + C(Group):C(Nfig):C(Tipo) + C(Group):C(Nfig):C(TargetPresence) + C(Group):C(Tipo):C(TargetPresence)'\n",
    "\n",
    "model2 = ols(formula2, df_ideal).fit()\n",
    "anova_table2 = sm.stats.anova_lm(model2, typ=2)\n",
    "\n",
    "print(anova_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e781336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 12. POST-HOC tests\n",
    "\n",
    "# See comment above for duplication\n",
    "\n",
    "# perform post-hoc test for 'Group'\n",
    "posthoc_group = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group'], alpha=0.05)\n",
    "print(posthoc_group)\n",
    "\n",
    "# perform post-hoc test for 'Nfig'\n",
    "posthoc_nfig = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Nfig'], alpha=0.05)\n",
    "print(posthoc_nfig)\n",
    "\n",
    "# perform post-hoc test for 'Tipo'\n",
    "posthoc_tipo = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Tipo'], alpha=0.05)\n",
    "print(posthoc_tipo)\n",
    "\n",
    "# perform post-hoc test for 'TargetPresence'\n",
    "posthoc_target_presence = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['TargetPresence'], alpha=0.05)\n",
    "print(posthoc_target_presence)\n",
    "\n",
    "# post-hoc test for 'Group:Nfig' interaction\n",
    "posthoc_group_nfig = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_Nfig'], alpha=0.05)\n",
    "print(posthoc_group_nfig)\n",
    "\n",
    "# post-hoc test for 'Group:Tipo' interaction\n",
    "posthoc_group_tipo = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_Tipo'], alpha=0.05)\n",
    "print(posthoc_group_tipo)\n",
    "\n",
    "# post-hoc test for 'Group:TargetPresence' interaction\n",
    "posthoc_group_target_presence = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_target_presence)\n",
    "\n",
    "# post-hoc test for 'Group:Nfig:Tipo' interaction\n",
    "posthoc_group_nfig_tipo = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_Nfig_Tipo'], alpha=0.05)\n",
    "print(posthoc_group_nfig_tipo)\n",
    "\n",
    "# post-hoc test for 'Group:Nfig:TargetPresence' interaction\n",
    "posthoc_group_nfig_target_presence = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_Nfig_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_nfig_target_presence)\n",
    "\n",
    "# post-hoc test for 'Group:Tipo:TargetPresence' interaction\n",
    "posthoc_group_tipo_target_presence = pairwise_tukeyhsd(df_ideal['Accuracy'], df_ideal['Group_Tipo_TargetPresence'], alpha=0.05)\n",
    "print(posthoc_group_tipo_target_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c861ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 13. visualization of mean Accuracy OLD vs YOUNG considering predictors interactions\n",
    "\n",
    "# calculate the mean Accuracy for each possible interaction of all levels of the conditions\n",
    "for Nfig in Nfig_levels:\n",
    "    for Tipo in Tipo_levels:\n",
    "        for TargetPresence in TargetPresence_levels:\n",
    "            for Group in Group_levels:\n",
    "                # filter the dataframe based on the current levels\n",
    "                df_filtered = df_ideal[(df_ideal['Nfig'] == Nfig) &\n",
    "                                                      (df_ideal['Tipo'] == Tipo) &\n",
    "                                                      (df_ideal['TargetPresence'] == TargetPresence) &\n",
    "                                                      (df_ideal['Group'] == Group)]\n",
    "                \n",
    "                # calculate the mean RT and standard error\n",
    "                mean_acc = df_filtered['Accuracy'].mean()\n",
    "                std_err_acc = df_filtered['Accuracy'].sem()\n",
    "                \n",
    "                # print the results\n",
    "                print(f\"Mean Accuracy for Nfig={Nfig}, Tipo={Tipo}, TargetPresence={TargetPresence}, Group={Group}: {mean_acc}, SE: {std_err_acc}\")\n",
    "\n",
    "# create two separate BAR plots according to TargetPresence\n",
    "for TargetPresence in TargetPresence_levels:\n",
    "    # filter the dataframe based on the current TargetPresence\n",
    "    df_filtered = df_ideal[df_ideal['TargetPresence'] == TargetPresence]\n",
    "    \n",
    "    # create a bar plot with error bars\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.barplot(data=df_filtered, x='Tipo_Nfig', y='Accuracy', hue='Group', palette=color_dict, capsize=.1)\n",
    "    \n",
    "    # get the unique 'Tipo_Nfig' values\n",
    "    unique_Tipo_Nfig = df_filtered['Tipo_Nfig'].unique()\n",
    "    \n",
    "    # add individual participant mean RT as jittered data points\n",
    "    for Group in Group_levels:\n",
    "        for i, Tipo_Nfig in enumerate(unique_Tipo_Nfig):\n",
    "            # filter the dataframe based on the current 'Tipo_Nfig' and 'Group'\n",
    "            df_filtered_Tipo_Nfig_Group = df_filtered[(df_filtered['Tipo_Nfig'] == Tipo_Nfig) & (df_filtered['Group'] == Group)]\n",
    "            \n",
    "            # get the unique participant IDs\n",
    "            IDs = df_filtered_Tipo_Nfig_Group['ID'].unique()\n",
    "            \n",
    "            # plot the mean RT for each participant\n",
    "            for ID in IDs:\n",
    "                # introduce a horizontal offset for both 'Young' and 'Old' groups\n",
    "                offset = -0.2 if Group == 'OLD' else 0.2\n",
    "                # marker = 'x' if Group == 'YOUNG' else 'o'\n",
    "                plt.scatter(i + offset + jitter_dict[(Nfig, Tipo, TargetPresence, Group, ID)], df_filtered_Tipo_Nfig_Group[df_filtered_Tipo_Nfig_Group['ID'] == ID]['Accuracy'].mean(), color=color_dict2[Group], alpha=0.5) #, marker=marker) \n",
    "    \n",
    "    plt.ylim(0.6, 1.1)  # Set y-axis range\n",
    "    plt.title(f'Mean Accuracy for each condition (TargetPresence = {TargetPresence})')\n",
    "    plt.xlabel('Condition (Tipo_Nfig)')\n",
    "    plt.ylabel('Mean Accuracy')\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "# create two separate BOXPLOTS according to TargetPresence\n",
    "for TargetPresence in TargetPresence_levels:\n",
    "    # filter the dataframe based on the current TargetPresence\n",
    "    df_filtered = df_ideal[df_ideal['TargetPresence'] == TargetPresence]\n",
    "    \n",
    "    # set size of the plot\n",
    "    plt.figure(figsize=(15, 8)) \n",
    "    # create a box plot with jittered data points\n",
    "    sns.boxplot(data=df_filtered, x='Tipo_Nfig', y='Accuracy', hue='Group', palette=color_dict)\n",
    "    \n",
    "    \n",
    "    # get the unique 'Tipo_Nfig' values\n",
    "    unique_Tipo_Nfig = df_filtered['Tipo_Nfig'].unique()\n",
    "    \n",
    "    # add individual participant mean RT as jittered data points\n",
    "    for Group in Group_levels:\n",
    "        for i, Tipo_Nfig in enumerate(unique_Tipo_Nfig):\n",
    "            # filter the dataframe based on the current 'Tipo_Nfig' and 'Group'\n",
    "            df_filtered_Tipo_Nfig_Group = df_filtered[(df_filtered['Tipo_Nfig'] == Tipo_Nfig) & (df_filtered['Group'] == Group)]\n",
    "            \n",
    "            # get the unique participant IDs\n",
    "            IDs = df_filtered_Tipo_Nfig_Group['ID'].unique()\n",
    "            \n",
    "            # plot the mean RT for each participant\n",
    "            for ID in IDs:\n",
    "                # introduce a horizontal offset for both 'Young' and 'Old' groups\n",
    "                offset = -0.2 if Group == 'OLD' else 0.2\n",
    "                # marker = 'x' if Group == 'YOUNG' else 'o'\n",
    "                plt.scatter(i + offset + jitter_dict[(Nfig, Tipo, TargetPresence, Group, ID)], df_filtered_Tipo_Nfig_Group[df_filtered_Tipo_Nfig_Group['ID'] == ID]['Accuracy'].mean(), color=color_dict2[Group], alpha=0.5) #, marker=marker) \n",
    "    \n",
    "    plt.ylim(0.6, 1.1)  # Set y-axis range\n",
    "    plt.title(f'Mean Accuracy for each condition (TargetPresence = {TargetPresence})')\n",
    "    plt.xlabel('Condition (Tipo_Nfig)')\n",
    "    plt.ylabel('Mean Accuracy')\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
